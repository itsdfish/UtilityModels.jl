var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"Modules = [UtilityModels]\nOrder   = [:type, :function]\nPrivate = false","category":"page"},{"location":"api/#UtilityModels.ExpectedUtility","page":"API","title":"UtilityModels.ExpectedUtility","text":"ExpectedUtility{T <: Real} <: UtilityModel\n\nA model object for expected utility theory\n\nFields\n\nα: utility curvature\nθ: temperature or decisional consistency\n\nConstructors\n\nExpectedUtility(; α = .80, θ = 1.0)\n\nExpectedUtility(α, θ)\n\nExample\n\nusing UtilityModels\n\ngamble1 = Gamble(; \n    p = [.25, .25, .50], \n    v = [44, 40, 5]\n)\n\ngamble2 = Gamble(; \n    p = [.25, .25, .50], \n    v = [98, 10, 5]\n)\n\ngambles = [gamble1,gamble2]\n\nmean.(model, gambles)\nstd.(model, gambles)\n\nmodel = ExpectedUtility(; α = .80, θ = 1.0)\n\npdf(model, gambles, 1)\n\nlogpdf(model, gambles, 1)\n\n\n\n\n\n","category":"type"},{"location":"api/#UtilityModels.Gamble","page":"API","title":"UtilityModels.Gamble","text":"Gamble{T <: Real}\n\nA gamble object with probability vector p and outcome vector v. \n\nFields\n\np: probability vector\nv: outcome vector\n\nConstructors\n\nGamble(; p = [0.5, 0.5], v = [10.0, 0.0])\n\nGamble(p, v)\n\n\n\n\n\n","category":"type"},{"location":"api/#UtilityModels.ProspectTheory","page":"API","title":"UtilityModels.ProspectTheory","text":"ProspectTheory{T <: Real} <: AbstractProspectTheory \n\nA model object for cummulative prospect theory.  By default, parameters for utility curvature and probability weigting are equal gains and losses.\n\nFields\n\nα = .80: utility curvature for gains\nβ = α: utility curvature for losses\nγg = .70: probability weighting parameter for gains \nγl = γg: probability weighting parameter for losses\nλ = 2.25: loss aversion parameter\nθ: temperature or decisional consistency\n\nConstructors\n\nProspectTheory(; α = 0.80, β = α, γg = 0.70, γl = γg, λ = 2.25, θ = 1.0)\n\nProspectTheory(α, β, γg, γl, λ, θ)\n\nExample\n\nusing UtilityModels\n\ngamble1 = Gamble(; \n    p = [.25, .25, .50], \n    v = [44, 40, 5]\n)\n\ngamble2 = Gamble(; \n    p = [.25, .25, .50], \n    v = [98, 10, 5]\n)\n\ngambles = [gamble1,gamble2]\n\nmean.(model, gambles)\nstd.(model, gambles)\n\nmodel = ProspectTheory(; \n    α = 0.80, \n    γg = 0.70, \n    λ = 2.25, \n    θ = 1.0\n)\n\npdf(model, gambles, 1)\n\nlogpdf(model, gambles, 1)\n\nReferences\n\nFennema, H., & Wakker, P. (1997). Original and cumulative prospect theory: A discussion of empirical differences. Journal of Behavioral Decision Making, 10(1), 53-64.\n\nTversky, A., & Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and uncertainty, 5(4), 297-323.\n\n\n\n\n\n","category":"type"},{"location":"api/#UtilityModels.TAX","page":"API","title":"UtilityModels.TAX","text":"TAX{T <: Real} <: AbstractTAX\n\nA model object for transfer of attention exchange.\n\nFields\n\nδ = 1.0: transfer of attention parameter\nγ = 1.0: probability weighting parameter\nβ = .70: utility curvature\nθ: temperature or decisional consistency\n\nConstructors\n\nTAX(; δ = -1.0, β = 1.0, γ = 0.70, θ = 1.0)\n\nTAX(δ, γ, β, θ)\n\nExample\n\nusing UtilityModels\n\ngamble1 = Gamble(; \n    p = [.25, .25, .50], \n    v = [44, 40, 5]\n)\n\ngamble2 = Gamble(; \n    p = [.25, .25, .50], \n    v = [98, 10, 5]\n)\n\ngambles = [gamble1,gamble2]\n\nmean.(model, gambles)\nstd.(model, gambles)\n\nmodel = TAX(; \n    δ = -1.0, \n    β = 1.0, \n    γ = 0.70, \n    θ = 1.0\n)\n\npdf(model, gambles, 1)\n\nlogpdf(model, gambles, 1)\n\nReferences\n\nBirnbaum, M. H., & Chavez, A. (1997). Tests of theories of decision making: Violations of branch independence and distribution independence. Organizational Behavior and Human Decision Processes, 71(2), 161-194. Birnbaum, M. H. (2008). New paradoxes of risky decision making. Psychological Review, 115(2), 463.\n\n\n\n\n\n","category":"type"},{"location":"api/#UtilityModels.UtilityModel","page":"API","title":"UtilityModels.UtilityModel","text":"UtilityModel <: DiscreteMultivariateDistribution\n\nUtilityModel is an abstract type for  utility-based models ````\n\n\n\n\n\n","category":"type"},{"location":"api/#UtilityModels.ValenceExpectancy","page":"API","title":"UtilityModels.ValenceExpectancy","text":"ValenceExpectancy{T <: Real} <: AbstractValenceExpectancy\n\nA model object for expected utility theory\n\nFields\n\nυ: a vector of expected utilities\nΔ: learning rate where Δ ∈ [0,1]\nα: utility shape parameter where α > 0\nλ: loss aversion where λ > 0\nc: temperature\n\nConstructors\n\nValenceExpectancy(; n_options, Δ, α = 0.80, λ, c)\n\nValenceExpectancy(Δ, α, λ, c)\n\n\n\n\n\n","category":"type"},{"location":"api/#Distributions.logpdf-Tuple{UtilityModel, Vector{<:Gamble}, Vector{<:Int64}}","page":"API","title":"Distributions.logpdf","text":"logpdf(model::UtilityModel, gambles::Vector{<:Gamble}, choice::Int)\n\nComputes the choice log probability for a vector of gambles. \n\nArguments\n\nmodel::UtilityModel: a utility model \ngambles::Vector{<:Gamble}: a vector of gambles representing a choice set\nchoice_idxs::Vector{<:Int}: indices for the chosen gambles\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{UtilityModel, Vector{<:Gamble}, Vector{<:Int64}}","page":"API","title":"Distributions.pdf","text":"pdf(model::UtilityModel, gambles::Vector{<:Gamble}, choice::Int)\n\nComputes the choice probability for a vector of gambles. \n\nArguments\n\nmodel::UtilityModel: a utility model \ngambles::Vector{<:Gamble}: a vector of gambles representing a choice set\nchoice_idxs::Vector{<:Int}: indices for the chosen gambles\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.mean-Tuple{UtilityModel, Gamble}","page":"API","title":"Statistics.mean","text":"mean(model::UtilityModel, gamble::Gamble)\n\nComputes mean or expected utility\n\nArguments\n\nmodel::UtilityModel: a model M <: UtilityModel\ngamble::Gamble: a gamble object\n\n````\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.mean-Tuple{UtilityModels.AbstractTAX, Gamble}","page":"API","title":"Statistics.mean","text":"mean(model::AbstractTAX, gamble::Gamble)\n\nComputes mean utility for the TAX model\n\nArguments\n\nmodel::AbstractTAX: a model M <: UtilityModel\ngamble::Gamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.std-Tuple{UtilityModel, Gamble}","page":"API","title":"Statistics.std","text":"std(model::UtilityModel, gamble::Gamble)\n\nComputes the standard deviation of the gamble\n\nArguments\n\nmodel::UtilityMode: a model M <: UtilityModel\ngamble::Gamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.var-Tuple{UtilityModel, Gamble}","page":"API","title":"Statistics.var","text":"var(model::UtilityModel, gamble::Gamble)\n\nComputes the variance of the gamble\n\nArguments\n\nmodel::UtilityModel: a utility model \ngamble::Gamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#UtilityModels.compute_utility-Tuple{ExpectedUtility, Gamble}","page":"API","title":"UtilityModels.compute_utility","text":"compute_utility(model::ExpectedUtility, gamble::Gamble)\n\nComputes utility of gamble outcomes according to expected utility theory.\n\nArguments\n\nmodel::ExpectedUtility: a model object for prospect theory\ngamble::Gamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#UtilityModels.compute_utility-Tuple{UtilityModels.AbstractProspectTheory, Any}","page":"API","title":"UtilityModels.compute_utility","text":"compute_utility(model::AbstractProspectTheory, gamble)\n\nComputes utility of gamble outcomes according to prospect theory\n\nArguments\n\nmodel::AbstractProspectTheory: a model object for prospect theory\ngamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#UtilityModels.compute_utility-Tuple{UtilityModels.AbstractTAX, Any}","page":"API","title":"UtilityModels.compute_utility","text":"compute_utility(model::AbstractTAX, gamble)\n\nComputes utility of gamble outcomes according to TAX\n\nArguments\n\nmodel::AbstractTAX: a model object for TAX\ngamble: a gamble object\n\n\n\n\n\n","category":"method"},{"location":"api/#UtilityModels.compute_utility-Tuple{ValenceExpectancy, Any}","page":"API","title":"UtilityModels.compute_utility","text":"compute_utility(model::ValenceExpectancy, outcomes::Vector)\n\ncompute_utility computes utility of gamble outcomes according to expected utility theory\n\nmodel: a model object for prospect theory\noutcomes: observed outcomes of decisions\n\n\n\n\n\n","category":"method"},{"location":"parameter_estimation/#Parameter-Estimation","page":"Parameter Estimation","title":"Parameter Estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"In this brief tutorial, we will demonstrate how to perform Bayesian parameter estimation using Turing.jl. For simplicity, we will estimate the utility curvature parameter of an expected utility model from 50 independent identically distributed observations from a single choice set. ","category":"page"},{"location":"parameter_estimation/#Load-Packages","page":"Parameter Estimation","title":"Load Packages","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"The first step is to load the required packages.","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"using Plots\nusing Random\nusing Turing\nusing UtilityModels\nRandom.seed!(6541)","category":"page"},{"location":"parameter_estimation/#Choice-Set","page":"Parameter Estimation","title":"Choice Set","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Next, we will create the choice set from two trinary gambles. The first gamble is less risky than the second gamble, as defined by lower variance.","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"gamble1 = Gamble(; \n    p = [.25, .25, .50], \n    v = [44, 40, 5]\n)","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"The second gamble is relatively more risky. ","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"gamble2 = Gamble(; \n    p = [.25, .25, .50], \n    v = [98, 10, 5]\n)","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"In the code block below, we combine the gambles into a vector representing the available options. In addition, we create a model object and generate 50 simulated choices. The gambles and simulated choices are combined into a single data structure so it can be passed to logpdf via Turing and subsequently parsed. ","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"gambles = [gamble1,gamble2]\neu_model = ExpectedUtility(; α = .80, θ = 1)\nchoices  = rand(eu_model, gambles, 50)\ndata = (gambles,choices)","category":"page"},{"location":"parameter_estimation/#Create-Turing-Model","page":"Parameter Estimation","title":"Create Turing Model","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Below, we create a turing model by prefixing a function with the @model macro. The function passes the data and defines two sampling statements: a prior distribution on the utlity curvature parameter, and a sampling statement for the data.","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"@model function model(data)\n    α ~ truncated(Normal(.8, 1), 0, Inf)\n    data ~ ExpectedUtility(; α, θ = 1)\nend","category":"page"},{"location":"parameter_estimation/#Estimate-Parameters","page":"Parameter Estimation","title":"Estimate Parameters","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Now that the Turing model has been defined, we can pass it, along with the data, to sample to perform Bayesian parameter estimation with an MCMC algorithm called the No-U-turn sampler. The function call below will sample 2,000 times from the posterior distribution (discarding the first 1,000 warmup samples), for 4 parallel chains.","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"chain = sample(model(data), NUTS(1000, .85), MCMCThreads(), 1000, 4)","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"┌ Info: Found initial step size\n└   ϵ = 0.0125\n┌ Info: Found initial step size\n└   ϵ = 0.025\n┌ Info: Found initial step size\n└   ϵ = 0.00625\n┌ Info: Found initial step size\n└   ϵ = 3.2\nChains MCMC chain (1000×13×4 Array{Float64, 3}):\n\nIterations        = 1001:1:2000\nNumber of chains  = 4\nSamples per chain = 1000\nWall duration     = 0.91 seconds\nCompute duration  = 3.03 seconds\nparameters        = α\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n           α    0.8031    0.0317    0.0009   1299.4792   1501.7839    1.0008      428.8710\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n           α    0.7346    0.7841    0.8055    0.8240    0.8591","category":"page"},{"location":"parameter_estimation/#Plot-Posterior-Distribution","page":"Parameter Estimation","title":"Plot Posterior Distribution","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"Inspection of the trace plot does not reveal any anomolies. The density plot shows that the posterior distribution is centered near the data generating value of alpha = 80 and spans roughtly between .75 and .85, suggesting good recovery of the parameter. ","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"plot(chain, grid = false)","category":"page"},{"location":"parameter_estimation/","page":"Parameter Estimation","title":"Parameter Estimation","text":"(Image: )","category":"page"},{"location":"expected_utility/#Expected-Utility-Theory","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Expected utility theory is a theory of rational decision making with roots in economics. According to expected utility theory, gambles are evaluated by computing an expected utility, and selecting the gamble with the highest expected utility. The expected utility is computed as a probability weighted sum across all possible outcomes, where the outcomes can undergo a transformation from objective to subjective units called utility. Note that many utility-based models can be conceptualized as a generalization of expected utility theory. ","category":"page"},{"location":"expected_utility/#Example","page":"Expected Utility Theory","title":"Example","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"In this example, we will demonstrate how to use expected utility theory with a choice between two gambles. ","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"using Plots\nusing Random\nusing UtilityModels","category":"page"},{"location":"expected_utility/#Load-Packages","page":"Expected Utility Theory","title":"Load Packages","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The first step is to load the required packages.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"using Plots\nusing Random\nusing UtilityModels\nRandom.seed!(8741)","category":"page"},{"location":"expected_utility/#Create-Choice-Set","page":"Expected Utility Theory","title":"Create Choice Set","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"We will consider the following two options in this example: mathbfG_1 = (58 20 56 20 2 60) and mathbfG_2 = (96 20 4 20 2 60). Note that the package can handle choices between an arbitrary number of options, each with an arbitrary number of outcomes.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"gamble1 = Gamble(; \n    p = [.20, .20, .60], \n    v = [58, 56, 2]\n)\n\ngamble2 = Gamble(; \n    p = [.20, .20, .60], \n    v = [96, 4, 2]\n)\ngambles = [gamble1,gamble2]","category":"page"},{"location":"expected_utility/#Create-Model-Object","page":"Expected Utility Theory","title":"Create Model Object","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"expected_utility/#Utility-Curvature","page":"Expected Utility Theory","title":"Utility Curvature","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The utility curvature parameter alpha controls whether the utility function is concave, linear, or convex. The utility function is given by:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"U(x) = mathrmsign(x)x^alpha","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The parameter alpha can be intrepreted in terms of risk profile as follows: ","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"risk averse: 0 geq alpha  1\nrisk neutral: alpha = 1\nrisk seeking: alpha  1","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The utility function U(x) is plotted below for a range of values of alpha.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"model = ExpectedUtility()\nvals = [-20:.5:20;]\ngamble = Gamble(; v = vals)\nαs = range(0, 1.5, length = 5) \nutilities = [compute_utility(ExpectedUtility(; α) , gamble) for α ∈ αs]\nutility_plot = plot(vals, utilities, xlabel = \"x\", ylabel = \"U(x)\", labels = αs', legendtitle = \"α\", grid = false)","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"</details>","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"utility_plot","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Below, we set the alpha parameter to a value associated with moderate risk aversion. ","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"α = .80","category":"page"},{"location":"expected_utility/#Decisional-Consistency","page":"Expected Utility Theory","title":"Decisional Consistency","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The parameter theta—sometimes known as decisional consistency or sensitivity—controls how deterministically a model selects the option with the higher expected utility. In the equation below, the probability of selecting x_i from choice set x_1dots x_n is computed with the soft max function.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Pr(X = x_i mid x_1 dots x_n) = frace^theta cdot mathrmEU(x_i)sum_j=1^n e^theta cdot mathrmEU(x_j)","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"As shown in the plot below,  parameter theta modulates the choice probability.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"vals = [-10:.1:10;]\nθs = range(0, 2, length = 5) \nprobs = [pdf(ExpectedUtility(; α = 1, θ) , [Gamble(; p = [1], v = [0]), Gamble(; p = [1], v=[v])], [1,0]) for v ∈ vals, θ ∈ θs]\nprob_plot = plot(reverse!(vals), probs, xlabel = \"U(A) - U(B)\", ylabel = \"Probability A\", labels = θs', legendtitle = \"θ\", grid = false)","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"</details>","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"prob_plot","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"We will set theta to the following value:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"θ = 1.0","category":"page"},{"location":"expected_utility/#Expected-Utility-Constructor","page":"Expected Utility Theory","title":"Expected Utility Constructor","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Now that values have been asigned to the parameters, we will pass them to ExpectedUtility to generate the model object.","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"dist = ExpectedUtility(; α, θ)","category":"page"},{"location":"expected_utility/#Expected-Utility","page":"Expected Utility Theory","title":"Expected Utility","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The expected utilities of each gamble can be computed via mean as demonstrated below:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"mean.(dist, gambles)","category":"page"},{"location":"expected_utility/#Standard-Deviation-Utility","page":"Expected Utility Theory","title":"Standard Deviation Utility","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The standard deviation of utilities of each gamble can be computed via std as demonstrated below:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"std.(dist, gambles)","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The larger standard deviation of the second gamble indicates it is a riskier option.  ","category":"page"},{"location":"expected_utility/#Simulate-Model","page":"Expected Utility Theory","title":"Simulate Model","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Now that the model is defined, we will generate 10 choices using rand. ","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":" choices = rand(dist, gambles, 10)","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"In the code block above, the output is a sample from a multinomial distribution in which the ","category":"page"},{"location":"expected_utility/#Compute-Choice-Probability","page":"Expected Utility Theory","title":"Compute Choice Probability","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The probability of choosing the first option can be obtained as follows: ","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"pdf(dist, gambles, [1,0])","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The relatively high choice probability for the first option makes sense in light of its higher expected value (and lower variance).","category":"page"},{"location":"expected_utility/#Multiple-Choice-Sets","page":"Expected Utility Theory","title":"Multiple Choice Sets","text":"","category":"section"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"The logic above can be easily extended to situations involving multiple choice sets by wrapping them in vectors. Consider the following situation involing two repetitions of two choice sets:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"choice_sets = [\n    [\n        Gamble(; p = [0.20, 0.20, 0.60], v = [58, 56, 2]),\n        Gamble(; p = [0.20, 0.20, 0.60], v = [96, 4, 2])\n    ],\n    [\n        Gamble(; p = [0.45, 0.45, 0.10], v = [58, 56, 2]),\n        Gamble(; p = [0.45, 0.45, 0.10], v = [96, 4, 2])\n    ]\n]","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Next, we simulate two choices for each choice set:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"choices = rand.(dist, choice_sets, [2,2])","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"Finally, we compute the joint choice probabilities for each choice set:","category":"page"},{"location":"expected_utility/","page":"Expected Utility Theory","title":"Expected Utility Theory","text":"choices = pdf.(dist, choice_sets, choices)","category":"page"},{"location":"bayes_factor/#Computing-the-Bayes-Factor","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/#Overview","page":"Computing the Bayes Factor","title":"Overview","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"In this tutorial, we will use the Bayes factor to compare the evidence for one model relative to another reference model. Computing the Bayes factor is challenging because it requires integrating the log likelihood over the model parameters. One method for approximating this complex integral is non-reversible parallel tempering (Bouchard-Côté et al., 2022) using  Pigeons.jl. ","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"In the tutorial below, we will compare two models which differ only in terms of assumptions about drift rate variability: the LBA and the RDM. The LBA assumes that the drift rate varies across trials and is otherwise deterministic, whereas the RDM assumes the drift rate varies within a trial as Gaussian noise, but not across trials. The difference between the models can be visualized with Plots.jl:","category":"page"},{"location":"bayes_factor/#RDM","page":"Computing the Bayes Factor","title":"RDM","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"using Random\nusing UtilityModels\nusing Plots","category":"page"},{"location":"bayes_factor/#Load-Packages","page":"Computing the Bayes Factor","title":"Load Packages","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"using LinearAlgebra\nusing Pigeons\nusing Random\nusing UtilityModels\nusing Turing","category":"page"},{"location":"bayes_factor/#Define-Choice-Sets","page":"Computing the Bayes Factor","title":"Define Choice Sets","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"The eight choice sets below were taken from Birnbaum (2008). ","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"choice_sets = [\n    [\n        Gamble(; p = [0.20, 0.20, 0.60], v = [58, 56, 2]),\n        Gamble(; p = [0.20, 0.20, 0.60], v = [96, 4, 2])\n    ],\n    [\n        Gamble(; p = [0.45, 0.45, 0.10], v = [58, 56, 2]),\n        Gamble(; p = [0.45, 0.45, 0.10], v = [96, 4, 2])\n    ],\n    [\n        Gamble(; p = [0.80, 0.10, 0.10], v = [110, 44, 40]),\n        Gamble(; p = [0.80, 0.10, 0.10], v = [110, 98, 10])\n    ],\n    [\n        Gamble(; p = [0.80, 0.10, 0.10], v = [98, 98, 2]),\n        Gamble(; p = [0.80, 0.10, 0.10], v = [40, 40, 2])\n    ],\n    [\n        Gamble(; p = [0.80, 0.10, 0.10], v = [98, 2, 2]),\n        Gamble(; p = [0.80, 0.10, 0.10], v = [40, 40, 2])\n    ],\n    [\n        Gamble(; p = [.05, .05, .90], v = [96, 12, 3]),\n        Gamble(; p = [.05, .05, .90], v = [52, 48, 3]),\n    ],\n    [\n        Gamble(; p = [.50, .25, .25], v = [0, -800, -1_000]),\n        Gamble(; p = [.50, .25, .25], v = [0, -200, -1_600]),\n    ],\n    [\n        Gamble(; p = [.25, .25, .25, .25], v = [2_000, 800, -800, -1_000]),\n        Gamble(; p = [.25, .25, .25, .25], v = [1_600, 1_200, -200, -1_600]),\n    ],\n    [\n        Gamble(; p = [.50, .25, .25], v = [0, 50, 50]),\n        Gamble(; p = [.50, .25, .25], v = [0, 0, 100]),\n    ],\n    [\n        Gamble(; p = [.50, .25, .25], v = [0, -50, -50]),\n        Gamble(; p = [.50, .25, .25], v = [0, 0, -100]),\n    ],\n    [\n        Gamble(; p = [.59, .20, .20, .01], v = [110, 49, 45, 4]),\n        Gamble(; p = [.59, .20, .20, .01], v = [110, 97, 11, 4]),\n    ],\n    [\n        Gamble(; p = [.59, .20, .20, .01], v = [4, 45, 49, 110]),\n        Gamble(; p = [.59, .20, .20, .01], v = [4, 11, 97, 110]),\n    ],\n    [\n        Gamble(; p = [.48, .48, .02], v = [48, 40, 2]),\n        Gamble(; p = [.48, .48, .02], v = [96, 4, 2]),\n    ]\n]","category":"page"},{"location":"bayes_factor/#Data-Generating-Model","page":"Computing the Bayes Factor","title":"Data-Generating Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"The next step is to generate simulated data for comparing the models. Here, we will assume that the LBA is the true data generating model:","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"Random.seed!(554)\nmodel = TAX(; \n    δ = .70, \n    β = .60, \n    γ = 0.70, \n    θ = 1.0\n)\n# repetitions per choice set\nns = fill(10, length(choice_sets))\nchoices = rand.(model, choice_sets, ns)\ndata = (choice_sets,choices)","category":"page"},{"location":"bayes_factor/#Define-Models","page":"Computing the Bayes Factor","title":"Define Models","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"The following code blocks define the models along with their prior distributions using Turing.jl. Notice that the models are identical except for the log likelihood function.","category":"page"},{"location":"bayes_factor/#TAX","page":"Computing the Bayes Factor","title":"TAX","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"@model function tax(data)\n    β ~ Gamma(.2, 4)\n    γ ~ Gamma(.2, 4)\n    δ ~ Normal(0, 2)\n    data ~ TAX(; δ, γ, β)\nend","category":"page"},{"location":"bayes_factor/#Prospect-Theory","page":"Computing the Bayes Factor","title":"Prospect Theory","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"@model function prospect_theory(data)\n    α ~ Gamma(.2, 4)\n    γg ~ Gamma(.2, 4)\n    λ ~ truncated(Normal(2, 5), 0, Inf)\n    data ~ ProspectTheory(; α, γg, λ)\nend","category":"page"},{"location":"bayes_factor/#Estimate-Marginal-Log-Likelihood","page":"Computing the Bayes Factor","title":"Estimate Marginal Log Likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"The next step is to run the pigeons function to estimate the marginal log likelihood for each model. ","category":"page"},{"location":"bayes_factor/#TAX-2","page":"Computing the Bayes Factor","title":"TAX","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"pt_tax = pigeons(target=TuringLogPotential(tax(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"────────────────────────────────────────────────────────────────────────────\n  #scans       Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2        3.3      -24.5   4.43e-56      0.634          1          1 \n        4       1.88       42.2      0.331      0.791          1          1 \n        8       3.05       40.2     0.0393      0.661          1          1 \n       16       3.33       41.1      0.364       0.63          1          1 \n       32       3.05       41.3      0.396      0.662          1          1 \n       64       3.52       40.6      0.423      0.609          1          1 \n      128       3.26       41.4       0.56      0.638          1          1 \n      256       3.45       40.8      0.564      0.617          1          1 \n      512       3.48       40.8      0.578      0.613          1          1 \n 1.02e+03       3.33       40.9      0.596      0.629          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/#Prospect-Theory-2","page":"Computing the Bayes Factor","title":"Prospect Theory","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"pt_prospect_theory = pigeons(target=TuringLogPotential(prospect_theory(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"────────────────────────────────────────────────────────────────────────────\n  #scans       Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       4.73       31.6   0.000606      0.475          1          1 \n        4       2.83       43.1       0.42      0.686          1          1 \n        8       3.05       39.8    0.00128      0.661          1          1 \n       16       3.46       41.2      0.268      0.615          1          1 \n       32       3.81       40.9      0.328      0.577          1          1 \n       64       3.16       40.6      0.404      0.649          1          1 \n      128       3.26       41.3      0.569      0.638          1          1 \n      256        3.3       40.6       0.56      0.633          1          1 \n      512       3.38       40.9       0.55      0.625          1          1 \n 1.02e+03       3.45       40.7      0.589      0.617          1          1","category":"page"},{"location":"bayes_factor/#Extract-marginal-log-likelihood","page":"Computing the Bayes Factor","title":"Extract marginal log likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"In the following code block, the function stepping_stone extracts that marginal log likelihood:","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"mll_lba = stepping_stone(pt_lba)\nmll_rdm = stepping_stone(pt_rdm)","category":"page"},{"location":"bayes_factor/#Compute-the-Bayes-Factor","page":"Computing the Bayes Factor","title":"Compute the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"The bayes factor is obtained by exponentiating the difference between marginal log likelihoods. The value of 1.21 indicates that the LBA is 1.21 times more likely to have generated the data. ","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"bf = exp(mll_lba - mll_rdm)","category":"page"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"1.2070298459526883","category":"page"},{"location":"bayes_factor/#References","page":"Computing the Bayes Factor","title":"References","text":"","category":"section"},{"location":"bayes_factor/","page":"Computing the Bayes Factor","title":"Computing the Bayes Factor","text":"Syed, S., Bouchard-Côté, A., Deligiannidis, G., & Doucet, A. (2022). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2), 321-350.","category":"page"},{"location":"gambles/#Gamble-Objects","page":"Gambles","title":"Gamble Objects","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"Gamble objects are a special type of categorical distribution which contain a n times 1 vector of possible outcomes and a corresponding n times 1 vector of outcome probabilities. The fields are","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"v: a vector of outcome values \np: a vector of outcome probabilities","category":"page"},{"location":"gambles/#Example","page":"Gambles","title":"Example","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"In this section, we will illustrate how to create a gamble object and how to use various methods with the gamble objects, such as computing expected values.","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"using Random\nusing UtilityModels","category":"page"},{"location":"gambles/#Load-Packages","page":"Gambles","title":"Load Packages","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"The first step is to load the required packages.","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"using Random\nusing UtilityModels\nRandom.seed!(9854)","category":"page"},{"location":"gambles/#Create-a-Gamble-Object","page":"Gambles","title":"Create a Gamble Object","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"The code block below illustrates how to construct a gamble object for the gamble mathbfG = (58 20 56 20 2 60).","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"gamble = Gamble(; \n    p = [.20, .20, .60], \n    v = [58, 56, 2]\n)","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"Note that the package can handle choices between an arbitrary number of options, each with an arbitrary number of outcomes.","category":"page"},{"location":"gambles/#Expected-Value","page":"Gambles","title":"Expected Value","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"The expected value can be computed as follows: ","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"mean(gamble)","category":"page"},{"location":"gambles/#Standard-Deviation","page":"Gambles","title":"Standard Deviation","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"The standard deviation can be computed as follows: ","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"std(gamble)","category":"page"},{"location":"gambles/#Sample-Random-Outcome","page":"Gambles","title":"Sample Random Outcome","text":"","category":"section"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"You can sample a random outcome from the gamble distribution with rand. Here is an example:","category":"page"},{"location":"gambles/","page":"Gambles","title":"Gambles","text":"rand(gamble)","category":"page"},{"location":"#UtilityModels.jl","page":"Home","title":"UtilityModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides a unified interface for developing and testing utility-based models of decision making. Utility-based models have roots in economics and cognitive science, and are bound together by their common assumption that options are evaluated by weighting and adding their features to form an overall impression called an expected utility. Consider a generic gamble, O = (x_1 p_1 dots  x_n p_n), where x_i is a possible outcome which occurs with probability p_i. The expected utility can be expressed in the following form: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"mathrmEU(O) = sum_i=1^n w(p_i) u(x_i)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where functions w(p) and u(x) transform objective probabilities and outcomes into subjective values. The option with a higher expected utility has a higher chance of selection. Utility-based models differ in their specification of w(p) and u(x).","category":"page"},{"location":"#Package-Ecosystem","page":"Home","title":"Package Ecosystem","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"UtilityModels.jl can be used with many packages in the Julia ecosystem because it uses the API defined in Distributions.jl. Here are a few examples of packages that are compatible with UtilityModels.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Distributions.jl: functions for probability distributions\nPigeons.jl: Bayesian parameter estimation and Bayes factors\nTuring.jl: Bayesian parameter estimation","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install a stable version of SequentialSamplingModels by running the following in the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add SequentialSamplingModels","category":"page"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The code block below compares the expected utility and expected value using the TAX model.  ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using UtilityModels\n# TAX with default values\nmodel = TAX()\n# trinary gamble\ngamble = Gamble(;\n    p = [.25,.25,.50],\n    v = [100.0,0.0,-50.0]\n)\n# expected utility vs. expected value\nmean(model, gamble), mean(gamble)","category":"page"},{"location":"prospect_theory/#Prospect-Theory","page":"Prospect Theory","title":"Prospect Theory","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Prospect theory is a generalization of expected utility theory designed to describe human decision making rather than propose a theory of optional decision making. In particular, prospect theory incorporates loss aversion and non-linear subjective probabilities to yield a more accurate description of human decision making. ","category":"page"},{"location":"prospect_theory/#Example","page":"Prospect Theory","title":"Example","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"In this example, we will demonstrate how to use prosepect theory with a choice between two gambles. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"using LaTeXStrings\nusing Plots\nusing Random\nusing UtilityModels","category":"page"},{"location":"prospect_theory/#Load-Packages","page":"Prospect Theory","title":"Load Packages","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The first step is to load the required packages.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"using LaTeXStrings\nusing Plots\nusing Random\nusing UtilityModels\nRandom.seed!(214)","category":"page"},{"location":"prospect_theory/#Create-Choice-Set","page":"Prospect Theory","title":"Create Choice Set","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"We will consider the following two options in this example: mathbfG_1 = (58 20 56 20 2 60) and mathbfG_2 = (96 20 4 20 2 60). Note that the package can handle choices between an arbitrary number of options, each with an arbitrary number of outcomes.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"gamble1 = Gamble(; \n    p = [.20, .20, .60], \n    v = [58, 56, 2]\n)\n\ngamble2 = Gamble(; \n    p = [.20, .20, .60], \n    v = [96, 4, 2]\n)\ngambles = [gamble1,gamble2]","category":"page"},{"location":"prospect_theory/#Create-Model-Object","page":"Prospect Theory","title":"Create Model Object","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"prospect_theory/#Utility-Function","page":"Prospect Theory","title":"Utility Function","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The utility function for prospect theory is given by:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"U(x) = begincases \n      x^alpha   geq 0 \n      -lambda x^beta  mathrm otherwise\nendcases","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Next, we will explain the three parameters alpha, beta, and lambda.","category":"page"},{"location":"prospect_theory/#Utility-Curvature","page":"Prospect Theory","title":"Utility Curvature","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The utility curvature parameters controls whether the utility function is concave, linear, or convex. Unlike expected utility theory, prospect theory allows the curvature to differ for gains and losses. However, for simplicity, we will assume alpha = beta. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The parameters alpha and beta can be intrepreted in terms of risk profile as follows: ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"risk averse: 0 geq alpha beta  1\nrisk neutral: alpha beta = 1\nrisk seeking: alpha beta  1","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The utility function U(x) is plotted below for a range of values of alpha.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"model = ProspectTheory()\nvals = [-20:.5:20;]\ngamble = Gamble(; v = vals)\nαs = range(0, 1.5, length = 5) \nutilities = [compute_utility(ProspectTheory(; α, λ = 1) , gamble) for α ∈ αs]\nutility_plot = plot(vals, utilities, xlabel = \"x\", ylabel = \"U(x)\", labels = αs', legendtitle = \"α\", grid = false, xlims = (-20,20), ylims = (-75, 75))","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"</details>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"utility_plot","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Below, we set the alpha parameter to a value associated with moderate risk aversion. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"α = β = .80","category":"page"},{"location":"prospect_theory/#Loss-Aversion","page":"Prospect Theory","title":"Loss Aversion","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The parameter lambda geq 1 for loss aversion embodies the notion that losses loom larger than gains. As shown in the utility function above, the utility of losses is scaled by parameter lambda to make it more impactful than a gain of equivalent magnitude. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The plot below illustrates the effect of varying lambda for alpha = beta = 80. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"model = ProspectTheory()\nvals = [-20:.5:20;]\ngamble = Gamble(; v = vals)\nλs = range(1, 2.5, length = 5) \nutilities = [compute_utility(ProspectTheory(; α = .80, λ) , gamble) for λ ∈ λs]\nloss_aversion_plot = plot(vals, utilities, xlabel = \"x\", ylabel = \"U(x)\", labels = λs', legendtitle = \"λ\", grid = false, lims = (-20,20))","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"</details>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"loss_aversion_plot","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"We will assign the following value to the loss aversion parameter:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"λ = 2","category":"page"},{"location":"prospect_theory/#Probability-Weighting","page":"Prospect Theory","title":"Probability Weighting","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"In prospect theory, outcome probabilities are not necessarily treated objectively. Instead, outcome probabilities are transformed into subjective weights, akin to the transformation of outcomes in the utility function. The weighting function is defined as follows:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"w(p) = fracp^gamma(p^gamma + (1 - p)^gamma)^frac1gamma","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"where parameter gamma controls the non-linear weighting. As shwon in the plot below, the behavior of the parameter gamma is defined on the following ranges:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"overweight small probabilities, underweight large probabilities: 0 geq gamma   1\nobjective weighting: gamma = 1\nunderweight small probabilities, overweight large probabilities: gamma  1","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"using UtilityModels: compute_weights\nmodel = ProspectTheory()\nprobs = 0:.005:1\nγgs = range(.5, 2, length = 5) \nweights = [compute_weights.(ProspectTheory(; α = .80) , probs, γg) for γg ∈ γgs]\nprobability_weight_plot  = plot(probs, weights, xlabel = \"p\", ylabel = \"W(p)\", labels = γgs', legendtitle = L\"\\gamma_g\", grid = false)\nplot!(probs, probs, color = :black, linestyle = :dash, label = \"\")","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"</details>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"probability_weight_plot","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"In its most general form, prospect theory includes a parameter gamma_g for the gain domain, and parameter gamma_l for the loss domain. For simplicity, we will assume gamma_g = gamma_l:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"γg = γl = 0.7","category":"page"},{"location":"prospect_theory/#Decisional-Consistency","page":"Prospect Theory","title":"Decisional Consistency","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The parameter theta—sometimes known as decisional consistency or sensitivity—controls how deterministically a model selects the option with the higher expected utility. In the equation below, the probability of selecting mathbfG_i from choice set mathbfG_1dots mathbfG_n is computed with the soft max function.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Pr(mathbfG_i mid mathbfG_1 dots mathbfG_n) = frace^theta cdot mathrmEU(mathbfG_i)sum_j=1^n e^theta cdot mathrmEU(mathbfG_j)","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"As shown in the plot below, parameter theta modulates the choice probability.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"<details><summary>Show Plotting Code</summary>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"vals = [-10:.1:10;]\nθs = range(0, 2, length = 5) \nprobs = [pdf(ProspectTheory(; α = 1, θ) , [Gamble(; p = [1], v = [0]), Gamble(; p = [1], v=[v])], [1,0]) for v ∈ vals, θ ∈ θs]\nprob_plot = plot(reverse!(vals), probs, xlabel = \"U(A) - U(B)\", ylabel = \"Probability A\", labels = θs', legendtitle = \"θ\", grid = false)","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"</details>","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"prob_plot","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"We will set theta to the following value:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"θ = 1.0","category":"page"},{"location":"prospect_theory/#Prospect-Theory-Constructor","page":"Prospect Theory","title":"Prospect Theory Constructor","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Now that values have been asigned to the parameters, we will pass them to ProspectTheory to generate the model object.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"dist = ProspectTheory(; α, β, λ, γg, γl, θ)","category":"page"},{"location":"prospect_theory/#Expected-Utility","page":"Prospect Theory","title":"Expected Utility","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The expected utilities of each gamble can be computed via mean as demonstrated below:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"mean.(dist, gambles)","category":"page"},{"location":"prospect_theory/#Standard-Deviation-Utility","page":"Prospect Theory","title":"Standard Deviation Utility","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The standard deviation of utilities of each gamble can be computed via std as demonstrated below:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"std.(dist, gambles)","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The larger standard deviation of the second gamble indicates it is a riskier option.  ","category":"page"},{"location":"prospect_theory/#Simulate-Model","page":"Prospect Theory","title":"Simulate Model","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Now that the model is defined, we will generate 10 choices using rand. ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":" choices = rand(dist, gambles, 10)","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"In the code block above, the output is a sample from a multinomial distribution in which the ","category":"page"},{"location":"prospect_theory/#Compute-Choice-Probability","page":"Prospect Theory","title":"Compute Choice Probability","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The probability of choosing the first option can be obtained as follows: ","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"pdf(dist, gambles, [1,0])","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The relatively high choice probability for the first option makes sense in light of its higher expected value (and lower variance).","category":"page"},{"location":"prospect_theory/#Multiple-Choice-Sets","page":"Prospect Theory","title":"Multiple Choice Sets","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"The logic above can be easily extended to situations involving multiple choice sets by wrapping them in vectors. Consider the following situation involing two repetitions of two choice sets:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"choice_sets = [\n    [\n        Gamble(; p = [0.20, 0.20, 0.60], v = [58, 56, 2]),\n        Gamble(; p = [0.20, 0.20, 0.60], v = [96, 4, 2])\n    ],\n    [\n        Gamble(; p = [0.45, 0.45, 0.10], v = [58, 56, 2]),\n        Gamble(; p = [0.45, 0.45, 0.10], v = [96, 4, 2])\n    ]\n]","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Next, we simulate two choices for each choice set:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"choices = rand.(dist, choice_sets, [2,2])","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Finally, we compute the joint choice probabilities for each choice set:","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"choices = pdf.(dist, choice_sets, choices)","category":"page"},{"location":"prospect_theory/#References","page":"Prospect Theory","title":"References","text":"","category":"section"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Fennema, H., & Wakker, P. (1997). Original and cumulative prospect theory: A discussion of empirical differences. Journal of Behavioral Decision Making, 10(1), 53-64.","category":"page"},{"location":"prospect_theory/","page":"Prospect Theory","title":"Prospect Theory","text":"Tversky, A., & Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and uncertainty, 5(4), 297-323.","category":"page"}]
}
